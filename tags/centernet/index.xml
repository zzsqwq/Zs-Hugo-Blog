<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CenterNet on Zs's Blog</title><link>https://www.zzsqwq.cn/tags/centernet/</link><description>Recent content in CenterNet on Zs's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 27 Jan 2021 11:50:00 +0000</lastBuildDate><atom:link href="https://www.zzsqwq.cn/tags/centernet/index.xml" rel="self" type="application/rss+xml"/><item><title>如何使用CenterNet做3D目标检测测试</title><link>https://www.zzsqwq.cn/posts/164/</link><pubDate>Wed, 27 Jan 2021 11:50:00 +0000</pubDate><guid>https://www.zzsqwq.cn/posts/164/</guid><description>&lt;h2 id="centernetobjects-as-points介绍">
CenterNet—Objects as Points介绍
&lt;a class="heading-link" href="#centernetobjects-as-points%e4%bb%8b%e7%bb%8d">
&lt;i class="fa fa-link" aria-hidden="true">&lt;/i>
&lt;/a>
&lt;/h2>
&lt;p>​ &lt;a href="https://github.com/xingyizhou/CenterNet">CenterNet&lt;/a>是一个anchor-free的目标检测网络，与YOLOv3相比，精度有所提升，此外他不仅能够用于2D目标检测，也能够用于人体姿态识别，3D目标检测等···&lt;/p>
&lt;h3 id="安装centernet">
安装CenterNet
&lt;a class="heading-link" href="#%e5%ae%89%e8%a3%85centernet">
&lt;i class="fa fa-link" aria-hidden="true">&lt;/i>
&lt;/a>
&lt;/h3>
&lt;p>​ 其实安装&lt;a href="https://github.com/xingyizhou/CenterNet">CenterNet&lt;/a>的过程就是一个配置环境的问题，直接跟着官方给出的这里&lt;a href="https://github.com/xingyizhou/CenterNet/blob/master/readme/INSTALL.md">Install.md&lt;/a>配置一下即可，十分推荐使用Conda来管理环境，这里给出我的环境给大家参考一下：&lt;/p>
&lt;blockquote>
&lt;p>Ubuntu = 18.04 LTS&lt;/p>
&lt;p>pytorch = 1.2.0&lt;/p>
&lt;p>python = 3.6.12&lt;/p>
&lt;p>torchvision = 0.4.0&lt;/p>
&lt;p>cuda = 10.2&lt;/p>
&lt;/blockquote>
&lt;p>​ 需要注意的是：&lt;/p>
&lt;ul>
&lt;li>官方给出的教程里面使用的是 &lt;code>pytorch 0.4.1&lt;/code>，但是我个人在实测过程中遇到了一些问题，遂安装网上的教程更改为 &lt;code>pytorch 1.2.0&lt;/code>，并且需要把 &lt;code>${CenterNet_Root}/src/lib/models/networks/DCNv2&lt;/code> 中的这个&lt;a href="https://github.com/CharlesShang/DCNv2">DCNv2&lt;/a>网络更改为官方的最新版。&lt;/li>
&lt;li>这里使用的cuda版本最好和你的显卡匹配，之前因为显卡驱动的一些问题导致重装了电脑，根据我们学长学姐的建议，最好直接去cuda官网那边去下载deb包直接安装。&lt;/li>
&lt;li>遇到环境配置问题可以先去Google一下，一般作者都在CenterNet&amp;rsquo;s Issues中给出了回复，如果没有，可以发邮件给作者询问，当然也可以发消息/邮箱给我，大家一起探讨一下~&lt;/li>
&lt;/ul>
&lt;h3 id="运行centernet的demo">
运行CenterNet的demo
&lt;a class="heading-link" href="#%e8%bf%90%e8%a1%8ccenternet%e7%9a%84demo">
&lt;i class="fa fa-link" aria-hidden="true">&lt;/i>
&lt;/a>
&lt;/h3>
&lt;p>​ 想要运行demo，首先要去 &lt;a href="https://github.com/xingyizhou/CenterNet/blob/master/readme/MODEL_ZOO.md">Model zoo&lt;/a> 中下载一下我们需要使用的model，2D目标检测使用的是 &lt;a href="https://drive.google.com/open?id=1pl_-ael8wERdUREEnaIfqOV_VF2bEVRT">ctdet_coco_dla_2x.pth&lt;/a> ，人体姿态评估使用的是 &lt;a href="https://drive.google.com/open?id=1PO1Ax_GDtjiemEmDVD7oPWwqQkUu28PI">multi_pose_dla_3x.pth&lt;/a> ，下载后统一将他们放在CenterNet根目录中的model文件夹中。&lt;/p>
&lt;p>​ 然后使用conda切换到CenterNet的环境，在终端中运行：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">python demo.py ctdet --demo &lt;span style="color:#e6db74">${&lt;/span>CenterNet_Root&lt;span style="color:#e6db74">}&lt;/span>/images/17790319373_bd19b24cfc_k.jpg --load_model ../models/ctdet_coco_dla_2x.pth
&lt;/code>&lt;/pre>&lt;/div>&lt;p>​ 这里需要注意的是 &lt;code>--demo&lt;/code> 后面的 &lt;code>${CenterNet_Root}/images/17790319373_bd19b24cfc_k.jpg&lt;/code> ，这里我使用的是官方给出的实例图片，它位于CenterNet根目录的images文件夹中，前面的 &lt;code>${CenterNet_Root} &lt;/code> 代表的是 CenterNet根目录，好比我的就位于 &lt;code>/home/zs/CenterNet&lt;/code> 。&lt;/p>
&lt;p>​ 如果不出意外的话效果应该如下图所示：&lt;/p>
&lt;p>&lt;img src="https://www.zzsqwq.cn/usr/uploads/2021/01/2469782097.jpg" alt="2D目标检测效果">&lt;/p>
&lt;h3 id="运行centernet的3d目标检测">
运行CenterNet的3D目标检测
&lt;a class="heading-link" href="#%e8%bf%90%e8%a1%8ccenternet%e7%9a%843d%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b">
&lt;i class="fa fa-link" aria-hidden="true">&lt;/i>
&lt;/a>
&lt;/h3>
&lt;h4 id="配置数据集和模型">
配置数据集和模型
&lt;a class="heading-link" href="#%e9%85%8d%e7%bd%ae%e6%95%b0%e6%8d%ae%e9%9b%86%e5%92%8c%e6%a8%a1%e5%9e%8b">
&lt;i class="fa fa-link" aria-hidden="true">&lt;/i>
&lt;/a>
&lt;/h4>
&lt;p>​ 我们可以直接参考官方的 &lt;code>DATA.md&lt;/code> 来配置我们的数据集。&lt;/p>
&lt;p>​ 然后到 &lt;a href="https://github.com/xingyizhou/CenterNet/blob/master/readme/MODEL_ZOO.md">Model zoo&lt;/a> 下载3D检测使用的模型 &lt;a href="https://drive.google.com/open?id=1znsM6E-aVTkATreDuUVxoU0ajL1az8rz">ddd_3dop.pth&lt;/a> 。&lt;/p>
&lt;p>​ 这里说一下遇到的几个坑：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>首先是配置数据集的过程中，我们需要配置的目录结构如图所示（官方给出的结构树有点模糊不清的感觉）&lt;/p>
&lt;pre tabindex="0">&lt;code>.
├── ImageSets_3dop
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
├── ImageSets_subcnn
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
└── training
├── calib
├── image_2
└── label_2
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>然后去到 &lt;code>${CenterNet_ROOT}/src/tools&lt;/code>目录下，运行 &lt;code>python convert_kitti_to_coco.py &lt;/code> 将 &lt;strong>kitti&lt;/strong> 数据集转换为 &lt;strong>coco&lt;/strong> 数据集的格式，不出意外应该会报错如下：&lt;/p>
&lt;p>&lt;img src="https://www.zzsqwq.cn/usr/uploads/2021/01/3420056939.png" alt="转换时报错">&lt;/p>
&lt;p>这里的解决方案参考CenterNet中的一个Issue , &lt;a href="https://github.com/xingyizhou/CenterNet/issues/54">How to generate the image dir in kitti?&lt;/a> ，我们需要回到 &lt;code>data/kitti&lt;/code> 目录下手动创建一个 &lt;code>annotations&lt;/code> 文件夹，然后再回去运行转换程序。转换后目录结构如下：&lt;/p>
&lt;pre tabindex="0">&lt;code>.
├── annotations
│   ├── kitti_3dop_train.json
│   ├── kitti_3dop_val.json
│   ├── kitti_subcnn_train.json
│   └── kitti_subcnn_val.json
├── ImageSets_3dop
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
├── ImageSets_subcnn
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
└── training
├── calib
├── image_2
└── label_2
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>然后根据官方的教程，我们需要创建一个images文件夹，然后将其 &lt;code>training/image_2&lt;/code> 链接到 &lt;code>images/trainval&lt;/code>，我在实际的测试中，发现此方法并不可行。参考CenterNet中的一个Issue: &lt;a href="https://github.com/xingyizhou/CenterNet/issues/575#">Evaluate kitti&amp;ndash;AttributeError: &amp;lsquo;NoneType&amp;rsquo; object has no attribute &amp;lsquo;shape&amp;rsquo;&lt;/a> ，其中 juanmed给出了解决方案：&lt;/p>
&lt;blockquote>
&lt;p>I had the same problem. For some reason the simlinks that are created during the data preparation process described in DATA.md are not working. So instead of creating simlinks I simply copied the actual data into the directories indicated in DATA.md. In other words the folders &lt;code>data/kitti/images/test&lt;/code> and &lt;code>data/kitti/images/trainval&lt;/code> do contain the actual images.&lt;/p>
&lt;/blockquote>
&lt;p>意思就是说，我们在 &lt;strong>images&lt;/strong> 中的图片必须都是真实的照片，而不能只是软链接过去。&lt;/p>
&lt;p>解决方案很显然，只需要在 &lt;strong>images&lt;/strong> 文件夹中建立一个 &lt;strong>trainval&lt;/strong> 文件夹，将 &lt;code>training/image_2&lt;/code> 中的所有图像都移入其中即可。如果有test的照片，那么也照规在 &lt;strong>images&lt;/strong> 新建一个 &lt;strong>test&lt;/strong> 文件夹，把测试的照片移入其中即可。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h4 id="运行测试程序">
运行测试程序
&lt;a class="heading-link" href="#%e8%bf%90%e8%a1%8c%e6%b5%8b%e8%af%95%e7%a8%8b%e5%ba%8f">
&lt;i class="fa fa-link" aria-hidden="true">&lt;/i>
&lt;/a>
&lt;/h4>
&lt;p>​ 接下来我们就可以根据官方给出的 &lt;a href="https://github.com/xingyizhou/CenterNet/blob/master/readme/GETTING_STARTED.md">GETTING_STARTED.md&lt;/a> 来进行我们的检测了。&lt;/p>
&lt;p>​ 即先编译一下评估工具，然后运行测试程序，但其实还是有一点点小问题。&lt;/p>
&lt;p>​ 具体问题可以参考 Issus: &lt;a href="https://github.com/xingyizhou/CenterNet/issues/55">kitti test: Couldn&amp;rsquo;t read: 006042.txt of ground truth.&lt;/a>&lt;/p>
&lt;p>​ Issue下 &lt;strong>lhyfst&lt;/strong> 已经给出了解决方案 ：&lt;/p>
&lt;blockquote>
&lt;p>The solution is quite simple.
&lt;code>cd data/kitti&lt;/code>
&lt;code>mv label_2 label_val&lt;/code>&lt;/p>
&lt;/blockquote>
&lt;p>​ 更改后，运行成功~&lt;/p>
&lt;p>​ 我们应该可以在 &lt;code>${CenterNet_ROOT}/exp/ddd/3dop/results&lt;/code> 看到我们得到的结果，只不过运行得到的是点的坐标，而不是图像，如果需要图像的话可能还需要自己绘制一下。&lt;/p></description></item></channel></rss>