<!doctype html><html lang=cn>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=content-language content="cn">
<meta name=color-scheme content="light dark">
<meta name=author content="zzsqwq">
<meta name=description content="CenterNet—Objects as Points介绍    ​	CenterNet是一个anchor-free的目标检测网络，与YOLOv3相比，精度有所提升，此外他不仅能够用于2D目标检测，也能够用于人体姿态识别，3D目标检测等···
安装CenterNet    ​	其实安装CenterNet的过程就是一个配置环境的问题，直接跟着官方给出的这里Install.md配置一下即可，十分推荐使用Conda来管理环境，这里给出我的环境给大家参考一下：
 Ubuntu = 18.04 LTS
pytorch = 1.2.0
python = 3.6.12
torchvision = 0.4.0
cuda = 10.2
 ​	需要注意的是：
 官方给出的教程里面使用的是 pytorch 0.4.1，但是我个人在实测过程中遇到了一些问题，遂安装网上的教程更改为 pytorch 1.2.0，并且需要把 ${CenterNet_Root}/src/lib/models/networks/DCNv2 中的这个DCNv2网络更改为官方的最新版。 这里使用的cuda版本最好和你的显卡匹配，之前因为显卡驱动的一些问题导致重装了电脑，根据我们学长学姐的建议，最好直接去cuda官网那边去下载deb包直接安装。 遇到环境配置问题可以先去Google一下，一般作者都在CenterNet&rsquo;s Issues中给出了回复，如果没有，可以发邮件给作者询问，当然也可以发消息/邮箱给我，大家一起探讨一下~  运行CenterNet的demo    ​	想要运行demo，首先要去 Model zoo 中下载一下我们需要使用的model，2D目标检测使用的是 ctdet_coco_dla_2x.pth ，人体姿态评估使用的是 multi_pose_dla_3x.pth ，下载后统一将他们放在CenterNet根目录中的model文件夹中。
​	然后使用conda切换到CenterNet的环境，在终端中运行：
python demo.py ctdet --demo ${CenterNet_Root}/images/17790319373_bd19b24cfc_k.jpg --load_model ../models/ctdet_coco_dla_2x.pth ​	这里需要注意的是 --demo 后面的 ${CenterNet_Root}/images/17790319373_bd19b24cfc_k.">
<meta name=keywords content="blog,developer,personal">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="如何使用CenterNet做3D目标检测测试">
<meta name=twitter:description content="CenterNet—Objects as Points介绍    ​	CenterNet是一个anchor-free的目标检测网络，与YOLOv3相比，精度有所提升，此外他不仅能够用于2D目标检测，也能够用于人体姿态识别，3D目标检测等···
安装CenterNet    ​	其实安装CenterNet的过程就是一个配置环境的问题，直接跟着官方给出的这里Install.md配置一下即可，十分推荐使用Conda来管理环境，这里给出我的环境给大家参考一下：
 Ubuntu = 18.04 LTS
pytorch = 1.2.0
python = 3.6.12
torchvision = 0.4.0
cuda = 10.2
 ​	需要注意的是：
 官方给出的教程里面使用的是 pytorch 0.4.1，但是我个人在实测过程中遇到了一些问题，遂安装网上的教程更改为 pytorch 1.2.0，并且需要把 ${CenterNet_Root}/src/lib/models/networks/DCNv2 中的这个DCNv2网络更改为官方的最新版。 这里使用的cuda版本最好和你的显卡匹配，之前因为显卡驱动的一些问题导致重装了电脑，根据我们学长学姐的建议，最好直接去cuda官网那边去下载deb包直接安装。 遇到环境配置问题可以先去Google一下，一般作者都在CenterNet&rsquo;s Issues中给出了回复，如果没有，可以发邮件给作者询问，当然也可以发消息/邮箱给我，大家一起探讨一下~  运行CenterNet的demo    ​	想要运行demo，首先要去 Model zoo 中下载一下我们需要使用的model，2D目标检测使用的是 ctdet_coco_dla_2x.pth ，人体姿态评估使用的是 multi_pose_dla_3x.pth ，下载后统一将他们放在CenterNet根目录中的model文件夹中。
​	然后使用conda切换到CenterNet的环境，在终端中运行：
python demo.py ctdet --demo ${CenterNet_Root}/images/17790319373_bd19b24cfc_k.jpg --load_model ../models/ctdet_coco_dla_2x.pth ​	这里需要注意的是 --demo 后面的 ${CenterNet_Root}/images/17790319373_bd19b24cfc_k.">
<meta property="og:title" content="如何使用CenterNet做3D目标检测测试">
<meta property="og:description" content="CenterNet—Objects as Points介绍    ​	CenterNet是一个anchor-free的目标检测网络，与YOLOv3相比，精度有所提升，此外他不仅能够用于2D目标检测，也能够用于人体姿态识别，3D目标检测等···
安装CenterNet    ​	其实安装CenterNet的过程就是一个配置环境的问题，直接跟着官方给出的这里Install.md配置一下即可，十分推荐使用Conda来管理环境，这里给出我的环境给大家参考一下：
 Ubuntu = 18.04 LTS
pytorch = 1.2.0
python = 3.6.12
torchvision = 0.4.0
cuda = 10.2
 ​	需要注意的是：
 官方给出的教程里面使用的是 pytorch 0.4.1，但是我个人在实测过程中遇到了一些问题，遂安装网上的教程更改为 pytorch 1.2.0，并且需要把 ${CenterNet_Root}/src/lib/models/networks/DCNv2 中的这个DCNv2网络更改为官方的最新版。 这里使用的cuda版本最好和你的显卡匹配，之前因为显卡驱动的一些问题导致重装了电脑，根据我们学长学姐的建议，最好直接去cuda官网那边去下载deb包直接安装。 遇到环境配置问题可以先去Google一下，一般作者都在CenterNet&rsquo;s Issues中给出了回复，如果没有，可以发邮件给作者询问，当然也可以发消息/邮箱给我，大家一起探讨一下~  运行CenterNet的demo    ​	想要运行demo，首先要去 Model zoo 中下载一下我们需要使用的model，2D目标检测使用的是 ctdet_coco_dla_2x.pth ，人体姿态评估使用的是 multi_pose_dla_3x.pth ，下载后统一将他们放在CenterNet根目录中的model文件夹中。
​	然后使用conda切换到CenterNet的环境，在终端中运行：
python demo.py ctdet --demo ${CenterNet_Root}/images/17790319373_bd19b24cfc_k.jpg --load_model ../models/ctdet_coco_dla_2x.pth ​	这里需要注意的是 --demo 后面的 ${CenterNet_Root}/images/17790319373_bd19b24cfc_k.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://zzsqwq.github.io/posts/164/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-01-27T11:50:00+00:00">
<meta property="article:modified_time" content="2021-01-27T11:50:00+00:00">
<title>
如何使用CenterNet做3D目标检测测试 · Zs's Blog
</title>
<link rel=canonical href=https://zzsqwq.github.io/posts/164/>
<link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin>
<link rel=stylesheet href=/css/coder.min.d9fddbffe6f27e69985dc5fe0471cdb0e57fbf4775714bc3d847accb08f4a1f6.css integrity="sha256-2f3b/+byfmmYXcX+BHHNsOV/v0d1cUvD2Eesywj0ofY=" crossorigin=anonymous media=screen>
<link rel=stylesheet href=/css/coder-dark.min.ccbbada2e264e4fdbf9b2181cccc2cdb289a63dc9520a1e96ac2b9a45778df29.css integrity="sha256-zLutouJk5P2/myGBzMws2yiaY9yVIKHpasK5pFd43yk=" crossorigin=anonymous media=screen>
<link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32>
<link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16>
<link rel=apple-touch-icon href=/images/apple-touch-icon.png>
<link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png>
<meta name=generator content="Hugo 0.89.4">
</head>
<body class="preload-transitions colorscheme-auto">
<div class=float-container>
<a id=dark-mode-toggle class=colorscheme-toggle>
<i class="fa fa-adjust fa-fw" aria-hidden=true></i>
</a>
</div>
<main class=wrapper>
<nav class=navigation>
<section class=container>
<a class=navigation-title href=/>
Zs's Blog
</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle>
<i class="fa fa-bars fa-fw" aria-hidden=true></i>
</label>
<ul class=navigation-list>
<li class=navigation-item>
<a class=navigation-link href=/about/>About</a>
</li>
<li class=navigation-item>
<a class=navigation-link href=/posts/>Blog</a>
</li>
<li class=navigation-item>
<a class=navigation-link href=/projects/>Projects</a>
</li>
<li class=navigation-item>
<a class=navigation-link href=/friends/>Friends</a>
</li>
<li class=navigation-item>
<a class=navigation-link href=/contact/>Contact Me</a>
</li>
</ul>
</section>
</nav>
<div class=content>
<section class="container post">
<article>
<header>
<div class=post-title>
<h1 class=title>
<a class=title-link href=https://zzsqwq.github.io/posts/164/>
如何使用CenterNet做3D目标检测测试
</a>
</h1>
</div>
<div class=post-meta>
<div class=date>
<span class=posted-on>
<i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2021-01-27T11:50:00Z>
January 27, 2021
</time>
</span>
<span class=reading-time>
<i class="fa fa-clock-o" aria-hidden=true></i>
</span>
</div>
<div class=categories>
<i class="fa fa-folder" aria-hidden=true></i>
<a href=/categories/%E6%9D%82%E5%AD%A6/>杂学</a>
<span class=separator>•</span>
<a href=/categories/ubuntu/>Ubuntu</a></div>
<div class=tags>
<i class="fa fa-tag" aria-hidden=true></i>
<span class=tag>
<a href=/tags/centernet/>CenterNet</a>
</span>
<span class=separator>•</span>
<span class=tag>
<a href=/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>神经网络</a>
</span></div>
</div>
</header>
<div>
<h2 id=centernetobjects-as-points介绍>
CenterNet—Objects as Points介绍
<a class=heading-link href=#centernetobjects-as-points%e4%bb%8b%e7%bb%8d>
<i class="fa fa-link" aria-hidden=true></i>
</a>
</h2>
<p>​ <a href=https://github.com/xingyizhou/CenterNet>CenterNet</a>是一个anchor-free的目标检测网络，与YOLOv3相比，精度有所提升，此外他不仅能够用于2D目标检测，也能够用于人体姿态识别，3D目标检测等···</p>
<h3 id=安装centernet>
安装CenterNet
<a class=heading-link href=#%e5%ae%89%e8%a3%85centernet>
<i class="fa fa-link" aria-hidden=true></i>
</a>
</h3>
<p>​ 其实安装<a href=https://github.com/xingyizhou/CenterNet>CenterNet</a>的过程就是一个配置环境的问题，直接跟着官方给出的这里<a href=https://github.com/xingyizhou/CenterNet/blob/master/readme/INSTALL.md>Install.md</a>配置一下即可，十分推荐使用Conda来管理环境，这里给出我的环境给大家参考一下：</p>
<blockquote>
<p>Ubuntu = 18.04 LTS</p>
<p>pytorch = 1.2.0</p>
<p>python = 3.6.12</p>
<p>torchvision = 0.4.0</p>
<p>cuda = 10.2</p>
</blockquote>
<p>​ 需要注意的是：</p>
<ul>
<li>官方给出的教程里面使用的是 <code>pytorch 0.4.1</code>，但是我个人在实测过程中遇到了一些问题，遂安装网上的教程更改为 <code>pytorch 1.2.0</code>，并且需要把 <code>${CenterNet_Root}/src/lib/models/networks/DCNv2</code> 中的这个<a href=https://github.com/CharlesShang/DCNv2>DCNv2</a>网络更改为官方的最新版。</li>
<li>这里使用的cuda版本最好和你的显卡匹配，之前因为显卡驱动的一些问题导致重装了电脑，根据我们学长学姐的建议，最好直接去cuda官网那边去下载deb包直接安装。</li>
<li>遇到环境配置问题可以先去Google一下，一般作者都在CenterNet&rsquo;s Issues中给出了回复，如果没有，可以发邮件给作者询问，当然也可以发消息/邮箱给我，大家一起探讨一下~</li>
</ul>
<h3 id=运行centernet的demo>
运行CenterNet的demo
<a class=heading-link href=#%e8%bf%90%e8%a1%8ccenternet%e7%9a%84demo>
<i class="fa fa-link" aria-hidden=true></i>
</a>
</h3>
<p>​ 想要运行demo，首先要去 <a href=https://github.com/xingyizhou/CenterNet/blob/master/readme/MODEL_ZOO.md>Model zoo</a> 中下载一下我们需要使用的model，2D目标检测使用的是 <a href="https://drive.google.com/open?id=1pl_-ael8wERdUREEnaIfqOV_VF2bEVRT">ctdet_coco_dla_2x.pth</a> ，人体姿态评估使用的是 <a href="https://drive.google.com/open?id=1PO1Ax_GDtjiemEmDVD7oPWwqQkUu28PI">multi_pose_dla_3x.pth</a> ，下载后统一将他们放在CenterNet根目录中的model文件夹中。</p>
<p>​ 然后使用conda切换到CenterNet的环境，在终端中运行：</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>python demo.py ctdet --demo <span style=font-weight:700;font-style:italic>${</span>CenterNet_Root<span style=font-weight:700;font-style:italic>}</span>/images/17790319373_bd19b24cfc_k.jpg --load_model ../models/ctdet_coco_dla_2x.pth 
</code></pre></div><p>​ 这里需要注意的是 <code>--demo</code> 后面的 <code>${CenterNet_Root}/images/17790319373_bd19b24cfc_k.jpg</code> ，这里我使用的是官方给出的实例图片，它位于CenterNet根目录的images文件夹中，前面的 <code>${CenterNet_Root} </code> 代表的是 CenterNet根目录，好比我的就位于 <code>/home/zs/CenterNet</code> 。</p>
<p>​ 如果不出意外的话效果应该如下图所示：</p>
<p><img src=https://www.zzsqwq.cn/usr/uploads/2021/01/2469782097.jpg alt=2D目标检测效果></p>
<h3 id=运行centernet的3d目标检测>
运行CenterNet的3D目标检测
<a class=heading-link href=#%e8%bf%90%e8%a1%8ccenternet%e7%9a%843d%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b>
<i class="fa fa-link" aria-hidden=true></i>
</a>
</h3>
<h4 id=配置数据集和模型>
配置数据集和模型
<a class=heading-link href=#%e9%85%8d%e7%bd%ae%e6%95%b0%e6%8d%ae%e9%9b%86%e5%92%8c%e6%a8%a1%e5%9e%8b>
<i class="fa fa-link" aria-hidden=true></i>
</a>
</h4>
<p>​ 我们可以直接参考官方的 <code>DATA.md</code> 来配置我们的数据集。</p>
<p>​ 然后到 <a href=https://github.com/xingyizhou/CenterNet/blob/master/readme/MODEL_ZOO.md>Model zoo</a> 下载3D检测使用的模型 <a href="https://drive.google.com/open?id=1znsM6E-aVTkATreDuUVxoU0ajL1az8rz">ddd_3dop.pth</a> 。</p>
<p>​ 这里说一下遇到的几个坑：</p>
<ul>
<li>
<p>首先是配置数据集的过程中，我们需要配置的目录结构如图所示（官方给出的结构树有点模糊不清的感觉）</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>.
├── ImageSets_3dop
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
├── ImageSets_subcnn
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
└── training
       ├── calib
       ├── image_2
       └── label_2
</code></pre></div></li>
<li>
<p>然后去到 <code>${CenterNet_ROOT}/src/tools</code>目录下，运行 <code>python convert_kitti_to_coco.py </code> 将 <strong>kitti</strong> 数据集转换为 <strong>coco</strong> 数据集的格式，不出意外应该会报错如下：</p>
<p><img src=https://www.zzsqwq.cn/usr/uploads/2021/01/3420056939.png alt=转换时报错></p>
<p>这里的解决方案参考CenterNet中的一个Issue , <a href=https://github.com/xingyizhou/CenterNet/issues/54>How to generate the image dir in kitti?</a> ，我们需要回到 <code>data/kitti</code> 目录下手动创建一个 <code>annotations</code> 文件夹，然后再回去运行转换程序。转换后目录结构如下：</p>
<div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>.
├── annotations
│   ├── kitti_3dop_train.json
│   ├── kitti_3dop_val.json
│   ├── kitti_subcnn_train.json
│   └── kitti_subcnn_val.json
├── ImageSets_3dop
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
├── ImageSets_subcnn
│   ├── test.txt
│   ├── train.txt
│   ├── trainval.txt
│   └── val.txt
└── training
       ├── calib
       ├── image_2
       └── label_2
</code></pre></div></li>
<li>
<p>然后根据官方的教程，我们需要创建一个images文件夹，然后将其 <code>training/image_2</code> 链接到 <code>images/trainval</code>，我在实际的测试中，发现此方法并不可行。参考CenterNet中的一个Issue: <a href=https://github.com/xingyizhou/CenterNet/issues/575#>Evaluate kitti&ndash;AttributeError: &lsquo;NoneType&rsquo; object has no attribute &lsquo;shape&rsquo;</a> ，其中 juanmed给出了解决方案：</p>
<blockquote>
<p>I had the same problem. For some reason the simlinks that are created during the data preparation process described in DATA.md are not working. So instead of creating simlinks I simply copied the actual data into the directories indicated in DATA.md. In other words the folders <code>data/kitti/images/test</code> and <code>data/kitti/images/trainval</code> do contain the actual images.</p>
</blockquote>
<p>意思就是说，我们在 <strong>images</strong> 中的图片必须都是真实的照片，而不能只是软链接过去。</p>
<p>解决方案很显然，只需要在 <strong>images</strong> 文件夹中建立一个 <strong>trainval</strong> 文件夹，将 <code>training/image_2</code> 中的所有图像都移入其中即可。如果有test的照片，那么也照规在 <strong>images</strong> 新建一个 <strong>test</strong> 文件夹，把测试的照片移入其中即可。</p>
</li>
</ul>
<h4 id=运行测试程序>
运行测试程序
<a class=heading-link href=#%e8%bf%90%e8%a1%8c%e6%b5%8b%e8%af%95%e7%a8%8b%e5%ba%8f>
<i class="fa fa-link" aria-hidden=true></i>
</a>
</h4>
<p>​ 接下来我们就可以根据官方给出的 <a href=https://github.com/xingyizhou/CenterNet/blob/master/readme/GETTING_STARTED.md>GETTING_STARTED.md</a> 来进行我们的检测了。</p>
<p>​ 即先编译一下评估工具，然后运行测试程序，但其实还是有一点点小问题。</p>
<p>​ 具体问题可以参考 Issus: <a href=https://github.com/xingyizhou/CenterNet/issues/55>kitti test: Couldn&rsquo;t read: 006042.txt of ground truth.</a></p>
<p>​ Issue下 <strong>lhyfst</strong> 已经给出了解决方案 ：</p>
<blockquote>
<p>The solution is quite simple.
<code>cd data/kitti</code>
<code>mv label_2 label_val</code></p>
</blockquote>
<p>​ 更改后，运行成功~</p>
<p>​ 我们应该可以在 <code>${CenterNet_ROOT}/exp/ddd/3dop/results</code> 看到我们得到的结果，只不过运行得到的是点的坐标，而不是图像，如果需要图像的话可能还需要自己绘制一下。</p>
</div>
<footer>
<script src=https://utteranc.es/client.js repo=zzsqwq/hugo-blog-comment issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script>
</footer>
</article>
</section>
</div>
<footer class=footer>
<section class=container>
©
2019 -
2021
zzsqwq
·
<a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.
</section>
</footer>
</main>
<script src=/js/coder.min.03b17769f4f91ae35667e1f2a1ca8c16f50562576cf90ff32b3179926914daa5.js integrity="sha256-A7F3afT5GuNWZ+HyocqMFvUFYlds+Q/zKzF5kmkU2qU="></script>
</body>
</html>