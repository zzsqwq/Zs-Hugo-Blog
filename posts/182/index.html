<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>利用神经网络进行波士顿房价预测 | Zs's Blog</title>
<meta name=keywords content="Python,神经网络,深度学习,pytorch,数模"><meta name=description content="前言
前一阵学校有五一数模节校赛，和朋友一起参加做B题，波士顿房价预测，算是第一次自己动手实现一个简单的小网络吧，虽然很简单，但还是想记录一下。
题目介绍
波士顿住房数据由哈里森和鲁宾菲尔德于1978年Harrison and Rubinfeld1收集。它包括了波士顿大区每个调查行政区的506个观察值。1980年Belsley et al.2曾对此数据做过分析。
数据一共14列，每一列的含义分别如下：

  
      
          英文简称
          详细含义
      
  
  
      
          CRIM
          城镇的人均犯罪率
      
      
          ZN
          大于25,000平方英尺的地块的住宅用地比例。
      
      
          INDUS
          每个镇的非零售业务英亩的比例。
      
      
          CHAS
          查尔斯河虚拟变量（如果环河，则等于1；否则等于0）
      
      
          NOX
          一氧化氮的浓度（百万分之几）
      
      
          RM
          每个住宅的平均房间数
      
      
          AGE
          1940年之前建造的自有住房的比例
      
      
          DIS
          到五个波士顿就业中心的加权距离
      
      
          RAD
          径向公路通达性的指标
      
      
          TAX
          每一万美元的全值财产税率
      
      
          PTRATIO
          各镇的师生比率
      
      
          B
          计算方法为 $1000(B_k-0.63)^2$，其中Bk是按城镇划分的非裔美国人的比例
      
      
          LSTAT
          底层人口的百分比(%)
      
      
          price
          自有住房数的中位数，单位（千美元）
      
  

基于上述数据，请完成以下问题：
建立波士顿房价预测模型并对预测结果进行评价。
问题分析
首先这道题目的很明确，数据一共是 $506×14$ 的一个矩阵，有十三维的自变量，通过建立一个模型来拟合回归出最终的因变量 price，即户主拥有住房价值的中位数。这是一个回归问题，综合考虑有以下两个思路


通过各种回归算法（GradientBoostingRegressor，RandomForestRegressor，ExtraTreesRegressor，LinearRegressor等）结合全部或部分自变量来回归最终的price


建立前馈神经网络模型，根据通用逼近定理，我们可以拟合此回归模型。


我们对上述模型来进行实现并确定评估标准来对他们进行比较，选择最优的模型作为预测模型。
算法流程
传统的回归算法
自变量的选择
首先，考虑到数据集中13列自变量其中某一些可能和最终的房价并无强相关性，如果全部使用进行预测可能会对模型引入噪声，因此我们首先计算了房价price与各个自变量之间的相关系数 $r$ ，其中 $r$ 计算公式如下：
$$
r = \frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum(x_i-\bar{x})^2\sum(y_i-\bar{y})^2}}
$$
其中 $x_i,y_i$ 为数据的每个分量，$\bar{x}，\bar{y}$ 为数据的均值
该系数反映了两变量之间的相关性，$r$ 的绝对值介于 $[0,1]$ 区间内，$|r|$ 越接近1，表示两数据相关性越高，反之越低。计算后结果如下："><meta name=author content="zzsqwq"><link rel=canonical href=https://blog.zzsqwq.cn/posts/182/><meta name=google-site-verification content="G-WF7TH97J9X"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.zzsqwq.cn/images/avatar.png><link rel=icon type=image/png sizes=16x16 href=https://blog.zzsqwq.cn/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.zzsqwq.cn/images/favicon-32x32.ico><link rel=apple-touch-icon href=https://blog.zzsqwq.cn/apple-touch-icon.png><link rel=mask-icon href=https://blog.zzsqwq.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://blog.zzsqwq.cn/posts/182/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-WF7TH97J9X"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WF7TH97J9X")}</script><meta property="og:title" content="利用神经网络进行波士顿房价预测"><meta property="og:description" content="前言
前一阵学校有五一数模节校赛，和朋友一起参加做B题，波士顿房价预测，算是第一次自己动手实现一个简单的小网络吧，虽然很简单，但还是想记录一下。
题目介绍
波士顿住房数据由哈里森和鲁宾菲尔德于1978年Harrison and Rubinfeld1收集。它包括了波士顿大区每个调查行政区的506个观察值。1980年Belsley et al.2曾对此数据做过分析。
数据一共14列，每一列的含义分别如下：

  
      
          英文简称
          详细含义
      
  
  
      
          CRIM
          城镇的人均犯罪率
      
      
          ZN
          大于25,000平方英尺的地块的住宅用地比例。
      
      
          INDUS
          每个镇的非零售业务英亩的比例。
      
      
          CHAS
          查尔斯河虚拟变量（如果环河，则等于1；否则等于0）
      
      
          NOX
          一氧化氮的浓度（百万分之几）
      
      
          RM
          每个住宅的平均房间数
      
      
          AGE
          1940年之前建造的自有住房的比例
      
      
          DIS
          到五个波士顿就业中心的加权距离
      
      
          RAD
          径向公路通达性的指标
      
      
          TAX
          每一万美元的全值财产税率
      
      
          PTRATIO
          各镇的师生比率
      
      
          B
          计算方法为 $1000(B_k-0.63)^2$，其中Bk是按城镇划分的非裔美国人的比例
      
      
          LSTAT
          底层人口的百分比(%)
      
      
          price
          自有住房数的中位数，单位（千美元）
      
  

基于上述数据，请完成以下问题：
建立波士顿房价预测模型并对预测结果进行评价。
问题分析
首先这道题目的很明确，数据一共是 $506×14$ 的一个矩阵，有十三维的自变量，通过建立一个模型来拟合回归出最终的因变量 price，即户主拥有住房价值的中位数。这是一个回归问题，综合考虑有以下两个思路


通过各种回归算法（GradientBoostingRegressor，RandomForestRegressor，ExtraTreesRegressor，LinearRegressor等）结合全部或部分自变量来回归最终的price


建立前馈神经网络模型，根据通用逼近定理，我们可以拟合此回归模型。


我们对上述模型来进行实现并确定评估标准来对他们进行比较，选择最优的模型作为预测模型。
算法流程
传统的回归算法
自变量的选择
首先，考虑到数据集中13列自变量其中某一些可能和最终的房价并无强相关性，如果全部使用进行预测可能会对模型引入噪声，因此我们首先计算了房价price与各个自变量之间的相关系数 $r$ ，其中 $r$ 计算公式如下：
$$
r = \frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum(x_i-\bar{x})^2\sum(y_i-\bar{y})^2}}
$$
其中 $x_i,y_i$ 为数据的每个分量，$\bar{x}，\bar{y}$ 为数据的均值
该系数反映了两变量之间的相关性，$r$ 的绝对值介于 $[0,1]$ 区间内，$|r|$ 越接近1，表示两数据相关性越高，反之越低。计算后结果如下："><meta property="og:type" content="article"><meta property="og:url" content="https://blog.zzsqwq.cn/posts/182/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-05-16T15:19:00+00:00"><meta property="article:modified_time" content="2021-05-16T15:19:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="利用神经网络进行波士顿房价预测"><meta name=twitter:description content="前言
前一阵学校有五一数模节校赛，和朋友一起参加做B题，波士顿房价预测，算是第一次自己动手实现一个简单的小网络吧，虽然很简单，但还是想记录一下。
题目介绍
波士顿住房数据由哈里森和鲁宾菲尔德于1978年Harrison and Rubinfeld1收集。它包括了波士顿大区每个调查行政区的506个观察值。1980年Belsley et al.2曾对此数据做过分析。
数据一共14列，每一列的含义分别如下：

  
      
          英文简称
          详细含义
      
  
  
      
          CRIM
          城镇的人均犯罪率
      
      
          ZN
          大于25,000平方英尺的地块的住宅用地比例。
      
      
          INDUS
          每个镇的非零售业务英亩的比例。
      
      
          CHAS
          查尔斯河虚拟变量（如果环河，则等于1；否则等于0）
      
      
          NOX
          一氧化氮的浓度（百万分之几）
      
      
          RM
          每个住宅的平均房间数
      
      
          AGE
          1940年之前建造的自有住房的比例
      
      
          DIS
          到五个波士顿就业中心的加权距离
      
      
          RAD
          径向公路通达性的指标
      
      
          TAX
          每一万美元的全值财产税率
      
      
          PTRATIO
          各镇的师生比率
      
      
          B
          计算方法为 $1000(B_k-0.63)^2$，其中Bk是按城镇划分的非裔美国人的比例
      
      
          LSTAT
          底层人口的百分比(%)
      
      
          price
          自有住房数的中位数，单位（千美元）
      
  

基于上述数据，请完成以下问题：
建立波士顿房价预测模型并对预测结果进行评价。
问题分析
首先这道题目的很明确，数据一共是 $506×14$ 的一个矩阵，有十三维的自变量，通过建立一个模型来拟合回归出最终的因变量 price，即户主拥有住房价值的中位数。这是一个回归问题，综合考虑有以下两个思路


通过各种回归算法（GradientBoostingRegressor，RandomForestRegressor，ExtraTreesRegressor，LinearRegressor等）结合全部或部分自变量来回归最终的price


建立前馈神经网络模型，根据通用逼近定理，我们可以拟合此回归模型。


我们对上述模型来进行实现并确定评估标准来对他们进行比较，选择最优的模型作为预测模型。
算法流程
传统的回归算法
自变量的选择
首先，考虑到数据集中13列自变量其中某一些可能和最终的房价并无强相关性，如果全部使用进行预测可能会对模型引入噪声，因此我们首先计算了房价price与各个自变量之间的相关系数 $r$ ，其中 $r$ 计算公式如下：
$$
r = \frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum(x_i-\bar{x})^2\sum(y_i-\bar{y})^2}}
$$
其中 $x_i,y_i$ 为数据的每个分量，$\bar{x}，\bar{y}$ 为数据的均值
该系数反映了两变量之间的相关性，$r$ 的绝对值介于 $[0,1]$ 区间内，$|r|$ 越接近1，表示两数据相关性越高，反之越低。计算后结果如下："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.zzsqwq.cn/posts/"},{"@type":"ListItem","position":2,"name":"利用神经网络进行波士顿房价预测","item":"https://blog.zzsqwq.cn/posts/182/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"利用神经网络进行波士顿房价预测","name":"利用神经网络进行波士顿房价预测","description":"前言 前一阵学校有五一数模节校赛，和朋友一起参加做B题，波士顿房价预测，算是第一次自己动手实现一个简单的小网络吧，虽然很简单，但还是想记录一下。\n题目介绍 波士顿住房数据由哈里森和鲁宾菲尔德于1978年Harrison and Rubinfeld1收集。它包括了波士顿大区每个调查行政区的506个观察值。1980年Belsley et al.2曾对此数据做过分析。\n数据一共14列，每一列的含义分别如下：\n英文简称 详细含义 CRIM 城镇的人均犯罪率 ZN 大于25,000平方英尺的地块的住宅用地比例。 INDUS 每个镇的非零售业务英亩的比例。 CHAS 查尔斯河虚拟变量（如果环河，则等于1；否则等于0） NOX 一氧化氮的浓度（百万分之几） RM 每个住宅的平均房间数 AGE 1940年之前建造的自有住房的比例 DIS 到五个波士顿就业中心的加权距离 RAD 径向公路通达性的指标 TAX 每一万美元的全值财产税率 PTRATIO 各镇的师生比率 B 计算方法为 $1000(B_k-0.63)^2$，其中Bk是按城镇划分的非裔美国人的比例 LSTAT 底层人口的百分比(%) price 自有住房数的中位数，单位（千美元） 基于上述数据，请完成以下问题：\n建立波士顿房价预测模型并对预测结果进行评价。\n问题分析 首先这道题目的很明确，数据一共是 $506×14$ 的一个矩阵，有十三维的自变量，通过建立一个模型来拟合回归出最终的因变量 price，即户主拥有住房价值的中位数。这是一个回归问题，综合考虑有以下两个思路\n通过各种回归算法（GradientBoostingRegressor，RandomForestRegressor，ExtraTreesRegressor，LinearRegressor等）结合全部或部分自变量来回归最终的price\n建立前馈神经网络模型，根据通用逼近定理，我们可以拟合此回归模型。\n我们对上述模型来进行实现并确定评估标准来对他们进行比较，选择最优的模型作为预测模型。\n算法流程 传统的回归算法 自变量的选择 首先，考虑到数据集中13列自变量其中某一些可能和最终的房价并无强相关性，如果全部使用进行预测可能会对模型引入噪声，因此我们首先计算了房价price与各个自变量之间的相关系数 $r$ ，其中 $r$ 计算公式如下： $$ r = \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2\\sum(y_i-\\bar{y})^2}} $$ 其中 $x_i,y_i$ 为数据的每个分量，$\\bar{x}，\\bar{y}$ 为数据的均值\n该系数反映了两变量之间的相关性，$r$ 的绝对值介于 $[0,1]$ 区间内，$|r|$ 越接近1，表示两数据相关性越高，反之越低。计算后结果如下：\n","keywords":["Python","神经网络","深度学习","pytorch","数模"],"articleBody":"前言 前一阵学校有五一数模节校赛，和朋友一起参加做B题，波士顿房价预测，算是第一次自己动手实现一个简单的小网络吧，虽然很简单，但还是想记录一下。\n题目介绍 波士顿住房数据由哈里森和鲁宾菲尔德于1978年Harrison and Rubinfeld1收集。它包括了波士顿大区每个调查行政区的506个观察值。1980年Belsley et al.2曾对此数据做过分析。\n数据一共14列，每一列的含义分别如下：\n英文简称 详细含义 CRIM 城镇的人均犯罪率 ZN 大于25,000平方英尺的地块的住宅用地比例。 INDUS 每个镇的非零售业务英亩的比例。 CHAS 查尔斯河虚拟变量（如果环河，则等于1；否则等于0） NOX 一氧化氮的浓度（百万分之几） RM 每个住宅的平均房间数 AGE 1940年之前建造的自有住房的比例 DIS 到五个波士顿就业中心的加权距离 RAD 径向公路通达性的指标 TAX 每一万美元的全值财产税率 PTRATIO 各镇的师生比率 B 计算方法为 $1000(B_k-0.63)^2$，其中Bk是按城镇划分的非裔美国人的比例 LSTAT 底层人口的百分比(%) price 自有住房数的中位数，单位（千美元） 基于上述数据，请完成以下问题：\n建立波士顿房价预测模型并对预测结果进行评价。\n问题分析 首先这道题目的很明确，数据一共是 $506×14$ 的一个矩阵，有十三维的自变量，通过建立一个模型来拟合回归出最终的因变量 price，即户主拥有住房价值的中位数。这是一个回归问题，综合考虑有以下两个思路\n通过各种回归算法（GradientBoostingRegressor，RandomForestRegressor，ExtraTreesRegressor，LinearRegressor等）结合全部或部分自变量来回归最终的price\n建立前馈神经网络模型，根据通用逼近定理，我们可以拟合此回归模型。\n我们对上述模型来进行实现并确定评估标准来对他们进行比较，选择最优的模型作为预测模型。\n算法流程 传统的回归算法 自变量的选择 首先，考虑到数据集中13列自变量其中某一些可能和最终的房价并无强相关性，如果全部使用进行预测可能会对模型引入噪声，因此我们首先计算了房价price与各个自变量之间的相关系数 $r$ ，其中 $r$ 计算公式如下： $$ r = \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2\\sum(y_i-\\bar{y})^2}} $$ 其中 $x_i,y_i$ 为数据的每个分量，$\\bar{x}，\\bar{y}$ 为数据的均值\n该系数反映了两变量之间的相关性，$r$ 的绝对值介于 $[0,1]$ 区间内，$|r|$ 越接近1，表示两数据相关性越高，反之越低。计算后结果如下：\nCRIM ZN INDUS CHAS NOX RM LSTAT -0.385832 0.360445 -0.483725 0.175260 -0.427321 0.695360 -0.737663 AGE DIS RAD TAX PTRATIO B -0.376955 0.249929 -0.381626 -0.468536 -0.507787 0.333461 观察结果可以发现，在给定的十三个变量中，LSTAT 与 price 的相关程度最高$(|r|\u003e0.7)$，其次是 RM 与PTRATIO $(|r|\u003e0.5)$，再者是 TAX,INDUS,NOX $(|r|\u003e0.4)$，除上述之外的七个变量都与 price 无较强的相关性，因此我们考虑使用六个相关性较强变量和十三个变量分别来对房价进行预测，并对他们进行对比，来寻找最优的回归模型。\n模型的构建 首先我们使用了sklearn中自带的 boston 数据集，并将整体数据集随机划分为了训练集和测试集两部分，所占比例分别为80%和20%。\n然后，我们利用Linear,Ridge,Lasso,ElasticNet,DecisionTree,GradientBoosting,RandomForest,ExtraTrees八种模型通过训练集对其进行训练。\n接下来，我们利用训练集拟合得到的模型，使用测试集对其进行测试，与 Ground Truth 进行对比，并通过 $R^2$ 来评价该预测结果，其中 $R^2$ 计算公式如下，其是衡量回归模型好坏的常见指标，其值一般处于[0,1]之间，$R^2$ 越接近1，说明模型的性能越好。 $$ R^2 = 1-\\frac{\\sum(\\hat{y_i}-y_i)^2}{\\sum(\\bar{y}-y_i)^2} $$\n最后，考虑到模型的训练及预测可能具有偶然性，因此我们对于每一个模型进行20次训练及预测，利用20次的结果对其进行综合评价。利用得到的结果绘制 箱线图 所得结果如下：\n分析最终结果可以发现，无论是使用六个相关性较强变量还是十三个变量来进行预测，GradientBoost（梯度提升决策树）回归模型都是最好的，此外，我们可以发现，利用十三个变量要比利用六个主要变量来进行预测比有着更好的效果。\n前馈神经网络 模型的构建 近年来，神经网络理论不断发展，前馈神经网络（多层感知机、全连接神经网络）越来越多的被利用到数据分析中，因此考虑使用前馈神经网络来解决此问题。\n前馈神经网络（全连接神经网络）的网络结构一般由三部分构成，输入层，隐藏层，以及输出层，输入层与输出层一般只有一层，隐藏层可有多层。中间利用非线性函数作为激活函数可以使得网络具有拟合非线性函数的能力\n根据通用近似定理:\n通用近似定理\n对于具有线性输出层和至少一个使用“挤压”性质的激活函数的隐藏层组成的前馈神经网络，只要其隐藏层神经元的数量足够，它可以以任意精度来近似任何从一个定义在实数空间中的有界闭集函数。\n只要隐藏层网络维度够高，就可以拟合任意的函数。\n考虑到我们的模型有六维or十三维的数据输入，因此我们建立两层前馈神经网络，中间具有一层隐藏层，维度为1000维，激活函数使用Relu，Relu函数有以下优点:\nRelu相比于传统的Sigmoid、Tanh，导数更加好求，反向传播就是不断的更新参数的过程，因为其导数不复杂形式简单，可以使得网络训练更快速。\n此外，当数值过大或者过小，Sigmoid，Tanh的导数接近于0，Relu为非饱和激活函数则不存在这种现象，可以很好的解决梯度消失的问题\nRelu函数及网络结构图如图所示：\n$$ Relu:f(x) = max(0,x) $$\n具体实现 利用流行的深度学习框架 Pytorch 来对模型进行实现。\n首先，将数据集随机划分为训练集和测试集两部分，分别占80%和20%，并将其转化为Pytorch中的张量形式。 然后，利用MinMaxScaler对输入数据进行归一化，利用下列公式将其统一归一化为 $[0,1]$ 之间，以求模型能够更快的收敛。 $$ MinMaxScaler:x^{*} = \\frac{x-min(x)}{max(x)-min(x)} $$\n接下来，构建网络模型，利用 mseloss 作为损失函数，在训练过程中利用反向传播使其最终收敛为0。 $$ MseLoss = \\frac{1}{2n}\\sum||y(x)-a^L(x)||^2 $$\n最后，我们设置网络的学习率为0.01，训练10000个epoch，发现其loss最终降低到0.3%左右，我们利用上文提到的 $R^2$ 对结果进行评估并与回归模型进行对比，通过观察图片可以发现，前馈神经网络相比于传统的回归模型有着更好的拟合效果， 20次预测得到的$R^2$平均值达到了0.95，此外中位数，最大值，最小值也要比回归模型更加优秀，因此我们采用前馈神经网络模型来对最后的房价进行预测。 最终预测 最终我们利用构建的前馈神经网络模型进行预测，利用测试集对其进行对比，绘制预测如下：\n​\n可以看到其中很多点都覆盖的很好，即预测准确。\n通过理论对模型进行量化分析，计算预测的 $R^2$ $$ R^2 = 1-\\frac{\\sum(\\hat{y_i}-y_i)^2}{\\sum(\\bar{y}-y_i)^2} = 1-0.01357 = 0.98643=98.643% $$ 可以发现 $R^2$ 十分接近1，说明回归模型性能良好，符合要求。\n实现代码 代码放在我的Github了，其中写了较详细的README，链接为 BostonPredict 参考链接 很系统的波士顿房价预测研究报告（期中作业）\n作业-机器学习-波士顿房价预测 四种回归算法\n基于Python预测波士顿房价\n波士顿房价预测——回归分析案例（献给初学者）\n","wordCount":"201","inLanguage":"en","datePublished":"2021-05-16T15:19:00Z","dateModified":"2021-05-16T15:19:00Z","author":{"@type":"Person","name":"zzsqwq"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.zzsqwq.cn/posts/182/"},"publisher":{"@type":"Organization","name":"Zs's Blog","logo":{"@type":"ImageObject","url":"https://blog.zzsqwq.cn/images/avatar.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.zzsqwq.cn/ accesskey=h title="Zs's Blog (Alt + H)">Zs's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.zzsqwq.cn/about title=About><span>About</span></a></li><li><a href=https://blog.zzsqwq.cn/archives title=Posts><span>Posts</span></a></li><li><a href=https://blog.zzsqwq.cn/friends title=Friends><span>Friends</span></a></li><li><a href=https://blog.zzsqwq.cn/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.zzsqwq.cn/>Home</a>&nbsp;»&nbsp;<a href=https://blog.zzsqwq.cn/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">利用神经网络进行波士顿房价预测</h1><div class=post-meta><span title='2021-05-16 15:19:00 +0000 UTC'>May 16, 2021</span>&nbsp;·&nbsp;zzsqwq&nbsp;|&nbsp;<a href=https://github.com/zzsqwq/zzsqwq.github.io/tree/master/content/posts/%e5%88%a9%e7%94%a8%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e8%bf%9b%e8%a1%8c%e6%b3%a2%e5%a3%ab%e9%a1%bf%e6%88%bf%e4%bb%b7%e9%a2%84%e6%b5%8b.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e5%89%8d%e8%a8%80 aria-label=前言>前言</a></li><li><a href=#%e9%a2%98%e7%9b%ae%e4%bb%8b%e7%bb%8d aria-label=题目介绍>题目介绍</a></li><li><a href=#%e9%97%ae%e9%a2%98%e5%88%86%e6%9e%90 aria-label=问题分析>问题分析</a></li><li><a href=#%e7%ae%97%e6%b3%95%e6%b5%81%e7%a8%8b aria-label=算法流程>算法流程</a><ul><li><a href=#%e4%bc%a0%e7%bb%9f%e7%9a%84%e5%9b%9e%e5%bd%92%e7%ae%97%e6%b3%95 aria-label=传统的回归算法>传统的回归算法</a><ul><li><a href=#%e8%87%aa%e5%8f%98%e9%87%8f%e7%9a%84%e9%80%89%e6%8b%a9 aria-label=自变量的选择>自变量的选择</a></li><li><a href=#%e6%a8%a1%e5%9e%8b%e7%9a%84%e6%9e%84%e5%bb%ba aria-label=模型的构建>模型的构建</a></li></ul></li><li><a href=#%e5%89%8d%e9%a6%88%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c aria-label=前馈神经网络>前馈神经网络</a><ul><li><a href=#%e6%a8%a1%e5%9e%8b%e7%9a%84%e6%9e%84%e5%bb%ba-1 aria-label=模型的构建>模型的构建</a></li><li><a href=#%e5%85%b7%e4%bd%93%e5%ae%9e%e7%8e%b0 aria-label=具体实现>具体实现</a></li></ul></li></ul></li><li><a href=#%e6%9c%80%e7%bb%88%e9%a2%84%e6%b5%8b aria-label=最终预测>最终预测</a></li><li><a href=#%e5%ae%9e%e7%8e%b0%e4%bb%a3%e7%a0%81 aria-label=实现代码>实现代码</a></li><li><a href=#%e5%8f%82%e8%80%83%e9%93%be%e6%8e%a5 aria-label=参考链接>参考链接</a></li></ul></div></details></div><div class=post-content><h3 id=前言>前言<a hidden class=anchor aria-hidden=true href=#前言>#</a></h3><p>前一阵学校有五一数模节校赛，和朋友一起参加做B题，波士顿房价预测，算是第一次自己动手实现一个简单的小网络吧，虽然很简单，但还是想记录一下。</p><h3 id=题目介绍>题目介绍<a hidden class=anchor aria-hidden=true href=#题目介绍>#</a></h3><p>波士顿住房数据由哈里森和鲁宾菲尔德于1978年Harrison and Rubinfeld<sup><a href=https://blog.zzsqwq.cn/usr/uploads/2021/05/406125417.png>1</a></sup>收集。它包括了波士顿大区每个调查行政区的506个观察值。1980年Belsley et al.<sup><a href=https://blog.zzsqwq.cn/usr/uploads/2021/05/3238192089.png>2</a></sup>曾对此数据做过分析。</p><p>数据一共14列，每一列的含义分别如下：</p><table><thead><tr><th>英文简称</th><th>详细含义</th></tr></thead><tbody><tr><td>CRIM</td><td>城镇的人均犯罪率</td></tr><tr><td>ZN</td><td>大于25,000平方英尺的地块的住宅用地比例。</td></tr><tr><td>INDUS</td><td>每个镇的非零售业务英亩的比例。</td></tr><tr><td>CHAS</td><td>查尔斯河虚拟变量（如果环河，则等于1；否则等于0）</td></tr><tr><td>NOX</td><td>一氧化氮的浓度（百万分之几）</td></tr><tr><td>RM</td><td>每个住宅的平均房间数</td></tr><tr><td>AGE</td><td>1940年之前建造的自有住房的比例</td></tr><tr><td>DIS</td><td>到五个波士顿就业中心的加权距离</td></tr><tr><td>RAD</td><td>径向公路通达性的指标</td></tr><tr><td>TAX</td><td>每一万美元的全值财产税率</td></tr><tr><td>PTRATIO</td><td>各镇的师生比率</td></tr><tr><td>B</td><td>计算方法为 $1000(B_k-0.63)^2$，其中Bk是按城镇划分的非裔美国人的比例</td></tr><tr><td>LSTAT</td><td>底层人口的百分比(%)</td></tr><tr><td><strong>price</strong></td><td>自有住房数的中位数，单位（千美元）</td></tr></tbody></table><p>基于上述数据，请完成以下问题：</p><p><strong>建立波士顿房价预测模型并对预测结果进行评价。</strong></p><h3 id=问题分析>问题分析<a hidden class=anchor aria-hidden=true href=#问题分析>#</a></h3><p>首先这道题目的很明确，数据一共是 $506×14$ 的一个矩阵，有十三维的自变量，通过建立一个模型来拟合回归出最终的因变量 price，即户主拥有住房价值的中位数。这是一个回归问题，综合考虑有以下两个思路</p><ol><li><p>通过各种回归算法（GradientBoostingRegressor，RandomForestRegressor，ExtraTreesRegressor，LinearRegressor等）结合全部或部分自变量来回归最终的price</p></li><li><p>建立前馈神经网络模型，根据通用逼近定理，我们可以拟合此回归模型。</p></li></ol><p>我们对上述模型来进行实现并确定评估标准来对他们进行比较，选择最优的模型作为预测模型。</p><h3 id=算法流程>算法流程<a hidden class=anchor aria-hidden=true href=#算法流程>#</a></h3><h4 id=传统的回归算法>传统的回归算法<a hidden class=anchor aria-hidden=true href=#传统的回归算法>#</a></h4><h5 id=自变量的选择>自变量的选择<a hidden class=anchor aria-hidden=true href=#自变量的选择>#</a></h5><p>首先，考虑到数据集中13列自变量其中某一些可能和最终的房价并无强相关性，如果全部使用进行预测可能会对模型引入噪声，因此我们首先计算了房价price与各个自变量之间的相关系数 $r$ ，其中 $r$ 计算公式如下：
$$
r = \frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum(x_i-\bar{x})^2\sum(y_i-\bar{y})^2}}
$$
其中 $x_i,y_i$ 为数据的每个分量，$\bar{x}，\bar{y}$ 为数据的均值</p><p>该系数反映了两变量之间的相关性，$r$ 的绝对值介于 $[0,1]$ 区间内，$|r|$ 越接近1，表示两数据相关性越高，反之越低。计算后结果如下：</p><table><thead><tr><th>CRIM</th><th>ZN</th><th>INDUS</th><th>CHAS</th><th>NOX</th><th>RM</th><th>LSTAT</th></tr></thead><tbody><tr><td>-0.385832</td><td>0.360445</td><td>-0.483725</td><td>0.175260</td><td>-0.427321</td><td>0.695360</td><td>-0.737663</td></tr><tr><td><strong>AGE</strong></td><td><strong>DIS</strong></td><td><strong>RAD</strong></td><td><strong>TAX</strong></td><td><strong>PTRATIO</strong></td><td><strong>B</strong></td><td></td></tr><tr><td>-0.376955</td><td>0.249929</td><td>-0.381626</td><td>-0.468536</td><td>-0.507787</td><td>0.333461</td><td></td></tr></tbody></table><p>观察结果可以发现，在给定的十三个变量中，<strong>LSTAT <strong>与 <strong>price</strong> 的相关程度最高$(|r|>0.7)$，其次是 <strong>RM</strong> 与</strong>PTRATIO</strong> $(|r|>0.5)$，再者是 <strong>TAX,INDUS,NOX</strong> $(|r|>0.4)$，除上述之外的七个变量都与 <strong>price</strong> 无较强的相关性，因此我们考虑使用六个相关性较强变量和十三个变量分别来对房价进行预测，并对他们进行对比，来寻找最优的回归模型。</p><h5 id=模型的构建>模型的构建<a hidden class=anchor aria-hidden=true href=#模型的构建>#</a></h5><ul><li><p>首先我们使用了sklearn中自带的 boston 数据集，并将整体数据集随机划分为了训练集和测试集两部分，所占比例分别为80%和20%。</p></li><li><p>然后，我们利用Linear,Ridge,Lasso,ElasticNet,DecisionTree,GradientBoosting,RandomForest,ExtraTrees八种模型通过训练集对其进行训练。</p></li><li><p>接下来，我们利用训练集拟合得到的模型，使用测试集对其进行测试，与 Ground Truth 进行对比，并通过 $R^2$ 来评价该预测结果，其中 $R^2$ 计算公式如下，其是衡量回归模型好坏的常见指标，其值一般处于[0,1]之间，$R^2$ 越接近1，说明模型的性能越好。
$$
R^2 = 1-\frac{\sum(\hat{y_i}-y_i)^2}{\sum(\bar{y}-y_i)^2}
$$</p></li><li><p>最后，考虑到模型的训练及预测可能具有偶然性，因此我们对于每一个模型进行20次训练及预测，利用20次的结果对其进行综合评价。利用得到的结果绘制 <strong>箱线图</strong> 所得结果如下：</p></li></ul><p><img alt=使用六变量和十三个变量进行拟合的对比 loading=lazy src=https://blog.zzsqwq.cn/usr/uploads/2021/05/406125417.png></p><p>分析最终结果可以发现，无论是使用六个相关性较强变量还是十三个变量来进行预测，GradientBoost（梯度提升决策树）回归模型都是最好的，此外，我们可以发现，利用十三个变量要比利用六个主要变量来进行预测比有着更好的效果。</p><h4 id=前馈神经网络>前馈神经网络<a hidden class=anchor aria-hidden=true href=#前馈神经网络>#</a></h4><h5 id=模型的构建-1>模型的构建<a hidden class=anchor aria-hidden=true href=#模型的构建-1>#</a></h5><p>近年来，神经网络理论不断发展，前馈神经网络（多层感知机、全连接神经网络）越来越多的被利用到数据分析中，因此考虑使用前馈神经网络来解决此问题。</p><p>前馈神经网络（全连接神经网络）的网络结构一般由三部分构成，输入层，隐藏层，以及输出层，输入层与输出层一般只有一层，隐藏层可有多层。中间利用非线性函数作为激活函数可以使得网络具有拟合非线性函数的能力</p><p>根据通用近似定理:</p><blockquote><p><strong>通用近似定理</strong></p><p>对于具有线性输出层和至少一个使用“挤压”性质的激活函数的隐藏层组成的前馈神经网络，只要其隐藏层神经元的数量足够，它可以以任意精度来近似任何从一个定义在实数空间中的有界闭集函数。</p></blockquote><p>只要隐藏层网络维度够高，就可以拟合任意的函数。</p><p>考虑到我们的模型有六维or十三维的数据输入，因此我们建立两层前馈神经网络，中间具有一层隐藏层，维度为1000维，激活函数使用Relu，Relu函数有以下优点:</p><ul><li><p>Relu相比于传统的Sigmoid、Tanh，导数更加好求，反向传播就是不断的更新参数的过程，因为其导数不复杂形式简单，可以使得网络训练更快速。</p></li><li><p>此外，当数值过大或者过小，Sigmoid，Tanh的导数接近于0，Relu为非饱和激活函数则不存在这种现象，可以很好的解决梯度消失的问题</p></li></ul><p>Relu函数及网络结构图如图所示：</p><p>$$
Relu:f(x) = max(0,x)
$$</p><p><img alt=构建的前馈神经网络结构图 loading=lazy src=https://blog.zzsqwq.cn/usr/uploads/2021/05/3238192089.png></p><h5 id=具体实现>具体实现<a hidden class=anchor aria-hidden=true href=#具体实现>#</a></h5><p>利用流行的深度学习框架 <strong>Pytorch</strong> 来对模型进行实现。</p><ul><li>首先，将数据集随机划分为训练集和测试集两部分，分别占80%和20%，并将其转化为Pytorch中的张量形式。</li><li>然后，利用MinMaxScaler对输入数据进行归一化，利用下列公式将其统一归一化为 $[0,1]$ 之间，以求模型能够更快的收敛。</li></ul><p>$$
MinMaxScaler:x^{*} = \frac{x-min(x)}{max(x)-min(x)}
$$</p><ul><li>接下来，构建网络模型，利用 mseloss 作为损失函数，在训练过程中利用反向传播使其最终收敛为0。</li></ul><p>$$
MseLoss = \frac{1}{2n}\sum||y(x)-a^L(x)||^2
$$</p><ul><li>最后，我们设置网络的学习率为0.01，训练10000个epoch，发现其loss最终降低到0.3%左右，我们利用上文提到的 $R^2$ 对结果进行评估并与回归模型进行对比，通过观察图片可以发现，前馈神经网络相比于传统的回归模型有着更好的拟合效果， 20次预测得到的$R^2$平均值达到了0.95，此外中位数，最大值，最小值也要比回归模型更加优秀，因此我们采用前馈神经网络模型来对最后的房价进行预测。</li></ul><p><img alt=添加前馈神经网络后与其他模型进行比较 loading=lazy src=https://blog.zzsqwq.cn/usr/uploads/2021/05/2897732866.png></p><p><img alt=训练过程中的loss曲线 loading=lazy src=https://blog.zzsqwq.cn/usr/uploads/2021/05/3640570809.jpg></p><h3 id=最终预测>最终预测<a hidden class=anchor aria-hidden=true href=#最终预测>#</a></h3><p>最终我们利用构建的前馈神经网络模型进行预测，利用测试集对其进行对比，绘制预测如下：</p><p><img alt=predict_groundtruth.png loading=lazy src=https://blog.zzsqwq.cn/usr/uploads/2021/05/1130005314.png></p><p>​</p><p>可以看到其中很多点都覆盖的很好，即预测准确。</p><p>通过理论对模型进行量化分析，计算预测的 $R^2$
$$
R^2 = 1-\frac{\sum(\hat{y_i}-y_i)^2}{\sum(\bar{y}-y_i)^2} = 1-0.01357 = 0.98643=98.643%
$$
可以发现 $R^2$ 十分接近1，说明回归模型性能良好，符合要求。</p><h3 id=实现代码>实现代码<a hidden class=anchor aria-hidden=true href=#实现代码>#</a></h3><p>代码放在我的Github了，其中写了较详细的README，链接为 <a href=https://github.com/zzsqwq/BostonPredict>BostonPredict</a></p><h3 id=参考链接>参考链接<a hidden class=anchor aria-hidden=true href=#参考链接>#</a></h3><ul><li><p><a href=https://zhuanlan.zhihu.com/p/89873990>很系统的波士顿房价预测研究报告（期中作业）</a></p></li><li><p><a href=https://www.cnblogs.com/gwj23/p/10604611.html>作业-机器学习-波士顿房价预测 四种回归算法</a></p></li><li><p><a href=https://zhuanlan.zhihu.com/p/48702850>基于Python预测波士顿房价</a></p></li><li><p><a href=https://cloud.tencent.com/developer/article/1574255>波士顿房价预测——回归分析案例（献给初学者）</a></p></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.zzsqwq.cn/tags/python/>Python</a></li><li><a href=https://blog.zzsqwq.cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>神经网络</a></li><li><a href=https://blog.zzsqwq.cn/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/>深度学习</a></li><li><a href=https://blog.zzsqwq.cn/tags/pytorch/>Pytorch</a></li><li><a href=https://blog.zzsqwq.cn/tags/%E6%95%B0%E6%A8%A1/>数模</a></li></ul><nav class=paginav><a class=prev href=https://blog.zzsqwq.cn/posts/195/><span class=title>« Prev</span><br><span>deepin-wine-qq-9.1.8版本无法正常启动的解决方案</span>
</a><a class=next href=https://blog.zzsqwq.cn/posts/173/><span class=title>Next »</span><br><span>2021RoboMaster中国赛比赛记录</span></a></nav></footer><div class=comments><script>let getTheme=window.localStorage&&window.localStorage.getItem("pref-theme");getTheme=getTheme??"preferred_color_scheme";let s=document.createElement("script");s.src="https://giscus.app/client.js",s.setAttribute("data-repo","zzsqwq/hugo-blog-comment"),s.setAttribute("data-repo-id","R_kgDOGgU1qQ"),s.setAttribute("data-category","Announcements"),s.setAttribute("data-category-id","DIC_kwDOGgU1qc4CSX1m"),s.setAttribute("data-mapping","pathname"),s.setAttribute("data-strict","0"),s.setAttribute("data-reactions-enabled","1"),s.setAttribute("data-emit-metadata","0"),s.setAttribute("data-input-position","top"),s.setAttribute("data-theme",getTheme),s.setAttribute("data-lang",""),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(s)</script></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.zzsqwq.cn/>Zs's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a> | <a href=http://beian.miit.gov.cn/ target=_blank>鲁ICP备2020034310号</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>function sendMessage(e){const t=document.querySelector("iframe.giscus-frame");if(!t)return;t.contentWindow.postMessage({giscus:e},"https://giscus.app")}document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light"),sendMessage({setConfig:{theme:"light"}})):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"),sendMessage({setConfig:{theme:"dark"}}))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>